---
title: "Server Implementation"
description: "Technical overview of the MemMachine backend architecture and service layer."
icon: "server"
---

The **MemMachine Server** is a FastAPI-based backend designed to orchestrate complex memory operations across episodic and semantic stores. While the Client SDK provides a high-level interface for users, the Server Implementation handles the heavy lifting of reference counting, instance caching, and cross-store search coordination.

## Service Architecture

The server is built around a "Shared Spec" architecture. Both the server and the client rely on a common set of Pydantic models (found in `spec.py`) to ensure that data validation is consistent across the network boundary.



### Core Architectural Pillars

| Component | Responsibility |
| :--- | :--- |
| **API Router** | Manages RESTful endpoints, dependency injection (e.g., `get_memmachine`), and Prometheus metric collection. |
| **Service Layer** | Translates incoming API specifications (`AddMemoriesSpec`) into internal storage models (`EpisodeEntry`). |
| **Memory Managers** | Orchestrates the lifecycle of memory instances, ensuring that resources like vector database connections are cached and released efficiently. |
| **Common Spec** | Defines the "Contract" between the server and the SDK, including Enums for `MemoryType` and `EpisodeType`. |

---

## Technical Organization

The server's logic is partitioned to mirror the two primary memory types:

### Episodic Logic
Focuses on the high-frequency ingestion of conversational data. The server implementation handles:
- **Metadata Casting:** Ensuring raw JSON metadata is properly typed for the vector store.
- **Context Injection:** Managing the `short_term_memory` and `long_term_memory` components within a single session.

### Semantic Logic
Focuses on structured knowledge organization. The server implementation handles:
- **Set & Category Management:** Creating the hierarchical structures (Sets -> Categories -> Tags) that organize long-term facts.
- **Template Application:** Managing category templates for consistent knowledge extraction.



from memmachine_server.main.memmachine import MemMachine, MemoryType
from memmachine_server.common.episode_store import EpisodeEntry
from memmachine_server.server.api_v2.mcp import initialize_resource

## Infrastructure Features

### Health & Monitoring
The server includes built-in endpoints for container orchestration (Kubernetes/Docker):
- `/health`: Returns service status and semantic versioning.
- `/metrics`: Exposes Prometheus-formatted metrics for request latency and memory ingestion counts.

### Dependency Injection
The server utilizes FastAPI dependencies to manage the `MemMachine` core instance, allowing for safe asynchronous access to the underlying storage engines across concurrent API requests.

---

## Next Steps

To dive deeper into the specific implementation details of each module, explore the following sections:

    print(f"Initializing MemMachine using {config_file}...")

    try:
        # Initialize MemMachine using the helper from mcp module which handles config loading
        mem_machine = await initialize_resource(config_file)

        # Create or get session
        session_key = "hello_session"
        print(f"Checking for session: {session_key}")

        session_info = await mem_machine.get_session(session_key=session_key)
        if session_info:
            print(f"Session {session_key} already exists, using it.")
        else:
            print(f"Creating session: {session_key}")
            # Note: create_session might fail if DBs are not reachable
            session_info = await mem_machine.create_session(session_key=session_key)

        # Wrap session info to satisfy SessionData protocol
        session = SessionDataWrapper(session_info)

        # Add a memory
        print("Adding memory...")
        episode = EpisodeEntry(
            content="Hello World! I am learning MemMachine.",
            producer_id="user1",
            producer_role="user",
            created_at=datetime.now(timezone.utc)
        )
        await mem_machine.add_episodes(
            session_data=session,
            episode_entries=[episode],
            target_memories=[MemoryType.Episodic]
        )

        # Search memory
        print("Searching memory...")
        results = await mem_machine.query_search(
            session_data=session,
            query="What am I learning?",
            limit=1
        )

        found = False
        if results.episodic_memory:
            # Check short-term memory
            if results.episodic_memory.short_term_memory and results.episodic_memory.short_term_memory.episodes:
                print(f"Found in Short Term Memory: {results.episodic_memory.short_term_memory.episodes[0].content}")
                found = True

            # Check long-term memory
            if results.episodic_memory.long_term_memory and results.episodic_memory.long_term_memory.episodes:
                print(f"Found in Long Term Memory: {results.episodic_memory.long_term_memory.episodes[0].content}")
                found = True

        if not found:
            print("No memory found (might need time to index or mock setup)")

        # Cleanup session
        print("Cleaning up session...")
        await mem_machine.delete_session(session)
        await mem_machine.stop()

    except Exception as e:
        import traceback
        traceback.print_exc()
        print(f"An error occurred: {e}")
        print("Ensure Neo4j is running and API keys are set in configuration.yml.")

if __name__ == "__main__":
    asyncio.run(main())

```

</Tab>
<Tab title="Expected Output">
When running inside the memmachine-app (server) Docker container, the output looks like this:
```bash expandable
root@bfd3cd481517:/app# python3 ./hello_world_server.py
Initializing MemMachine using configuration.yml...
Checking for session: hello_session
Creating session: hello_session
Adding memory...
2025-12-06 00:39:37,443 [INFO] httpx - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-12-06 00:39:37,474 [INFO] neo4j.notifications - Received notification from DBMS server: <GqlStatusObject gql_status='03N90', status_description='info: cartesian product. The disconnected patterns `(source:SANITIZED_Derivative_u5f_hello_u5f_session {uid: edge.source_uid}), (target:SANITIZED_Episode_u5f_hello_u5f_session {uid: edge.target_uid})` build a cartesian product. A cartesian product may produce a large amount of data and slow down query processing.', position=<SummaryInputPosition line=2, column=1, offset=22>, raw_classification='PERFORMANCE', classification=<NotificationClassification.PERFORMANCE: 'PERFORMANCE'>, raw_severity='INFORMATION', severity=<NotificationSeverity.INFORMATION: 'INFORMATION'>, diagnostic_record={'_classification': 'PERFORMANCE', '_status_parameters': {'pat': '(source:SANITIZED_Derivative_u5f_hello_u5f_session {uid: edge.source_uid}), (target:SANITIZED_Episode_u5f_hello_u5f_session {uid: edge.target_uid})'}, '_severity': 'INFORMATION', '_position': {'offset': 22, 'line': 2, 'column': 1}, 'OPERATION': '', 'OPERATION_CODE': '0', 'CURRENT_SCHEMA': '/'}> for query: 'UNWIND $edges AS edge\nMATCH    (source:SANITIZED_Derivative_u5f_hello_u5f_session {uid: edge.source_uid}),    (target:SANITIZED_Episode_u5f_hello_u5f_session {uid: edge.target_uid})\nCREATE (source)    -[r:SANITIZED_DERIVED_u5f_FROM_u5f_hello_u5f_session {uid: edge.uid}]->    (target)\nSET r += edge.properties'
Searching memory...
2025-12-06 00:39:37,480 [INFO] alembic.runtime.migration - Context impl PostgresqlImpl.
2025-12-06 00:39:37,480 [INFO] alembic.runtime.migration - Will assume transactional DDL.
2025-12-06 00:39:38,200 [INFO] httpx - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-12-06 00:39:38,669 [INFO] httpx - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
Found in Short Term Memory: Hello World! I am learning MemMachine.
Cleaning up session...
```
</Tab>
</Tabs>

### Useful Tips for Working in a Docker Container

**Connecting to a running MemMachine Server Container**

To connect to the `memmachine-app` container with an interactive Bash shell, run this from the host:
```bash
docker exec -it memmachine-app /bin/bash
```
You'll see a new prompt similar to this, which confirms you're inside the container:
```bash
root@bfd3cd481517:/app#
```

**Creating files inside the container**

This method is intended for testing only; it should not be used for developing applications.
`vim` and other editors are not available. Instead, use:
```bash
cat > my_file.py << 'EOF'
# Paste your code here
EOF
```

## Core Concepts

The Python Server SDK exposes several key APIs for managing memories. These are the foundational concepts for understanding server interactions:

### Episodic Memory (`episodic_memory`)

- Manages short-term memory tied to a user, agent, and session.
- Stores conversation-like events that are context-specific and transient.
- Main system calls: `add()`, `search()`, `get_all()`.

### Episodic Memory Manager (`episodic_memory_manager`)

- Provides management utilities for episodic memories across multiple sessions or users.
- Handles session lifecycle, cleanup, and advanced memory queries.

### Profile Memory (`profile_memory`)

- Manages long-term, persistent user memory.
- Stores attributes like preferences, traits, or other semantic knowledge.
- Main system calls: `upsert()`, `get_all()`, `delete()`.

### Memory Types (`memory_types`)

- Defines the different types of memories available: episodic, profile, and possibly hybrid semantic stores.
- Provides a consistent interface for creating, retrieving, and interacting with each memory type.

## Intended Audience

The MemMachine Python Server SDK is best suited for:

- Developers or teams who need to **self-host** their memory backend for maximum control and data privacy.
- Scenarios where **multiple agents, services, or languages** need to access a shared memory store.
- Use cases requiring **custom configuration** (storage, LLM provider, scaling, network topology) beyond what a managed solution provides.
