---
title: "Install Guide Resources"
description: "Your Home for Install Guide and Model specific Configuration Instructions"
icon: "download"
---

MemMachine offers flexible installation options to meet diverse development needs. Choose the method that best fits your environment, whether you are starting fresh or integrating with specific AI backends.

## Standard Installation
Access the main guide for installing MemMachine using the preferred methods:
<Columns cols={2}>
<Card title="Using PIP or Source" icon="file-image" href="/install_guide/install_guide">
  **Quickest Start for Most Developers.** The simplest, one-line setup using Python's package manager. **Recommended for all users** integrating MemMachine into an existing project.
</Card>
<Card title="Configure Wizard Guide" icon="hat-wizard" href="/install_guide/configure_wizard">
  **Configuration wizard for manual installation** A detailed guide for using a Wizard to assist with MemMachine Configuration. **Ideal for contributors** and active development.
</Card>
</Columns>

## Configurations
Find a **Quickstart Guide** and specific details for setting up MemMachine's backend with popular AI platforms:
<Columns cols={2}>
<Card title="Using Ollama Models" icon="paw" href="/install_guide/config/ollama">
  **Self-Host Your AI Backend.** Instructions for configuring MemMachine to use Ollama for local, open-source LLM and embedding models, maximizing privacy and control.
</Card>
<Card title="Using AWS Bedrock" icon="aws" href="/install_guide/config/aws_bedrock">
  **Scale with AWS Managed Services.** Learn how to leverage AWS Bedrock's enterprise-ready models for reliable, high-volume memory management and processing.
</Card>
</Columns>

## Integrations
Find specific configuration and integration details for using MemMachine in popular AI applications and workflows:

<Card title="OpenAI GPTStore" icon="openai" href="/install_guide/integrate/GPTStore" horizontal>
  **Persistent Memory for Custom GPTs.** Our most popular integration. Learn how to set up MemMachine as a **Custom Action** to furnish your GPTs with reliable, long-term memory and accurate user history.
</Card>

<Columns cols={3}>
  <Card title="Claude Code and MCP" icon="star-of-life" href="/install_guide/integrate/claude_code_mcp">
    **Give Claude Real-Time Recall.** Configure the MemMachine Control Protocol (MCP) as a **Custom Tool** to provide Claude with persistent user profiles.
  </Card>

  <Card title="LangGraph" icon="circle-nodes" href="/install_guide/integrate/LangGraph">
    **Master State and Workflow.** A practical guide to integrating MemMachine into your graph chains for managing **complex agent handoffs**.
  </Card>

  <Card title="CrewAI" icon="people-group" href="/install_guide/integrate/crewai">
    **Empower Agent Squads.** Enable cross-agent knowledge sharing, user preference tracking, and context retention across multi-task workflows.
  </Card>

  <Card title="n8n" icon="diagram-project" href="/install_guide/integrate/n8n">
    **No-Code Memory for n8n.** Install our community nodes to give your n8n AI agents persistent recall and deep context windowing.
  </Card>

  <Card title="Dify" icon="rocket" href="/install_guide/integrate/dify">
    **Build State-of-the-Art LLM Apps.** Add MemMachine as a Custom Tool Provider in Dify for your self-hosted or cloud agents.
  </Card>

  <Card title="Google ADK" icon="google" href="/install_guide/integrate/Google_ADK">
    **Extend Google GenAI.** Integrate MemMachine as a `BaseMemoryService` to empower Gemini agents to recall past interactions.
  </Card>
</Columns>
